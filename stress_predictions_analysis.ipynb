{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please change the value to access subject details. eg: '02' , '08', '20'\n",
    "num ='20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_logs = pd.read_excel('time_logs.xlsx')\n",
    "# /Users/karthikningala/CE888-DATA SCIENCE AND DECISION MAKING/Time_logs.xlsx\n",
    "time_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the time logs into intervals\n",
    "s=time_logs.loc[time_logs['S. ID.']==f'S{num}']\n",
    "stroop_test = s['Stroop Test']\n",
    "relax1 = s['Relax']\n",
    "interview=s['Interview']\n",
    "relax2=s['Relax.1']\n",
    "hyperventilation = s['Hyperventilation']\n",
    "relax3 = s['Relax.2']\n",
    "\n",
    "list_of_test = [stroop_test,relax1,interview,relax2,hyperventilation,relax3]\n",
    "time_logs = []\n",
    "stroop_test.astype(str).values[0]\n",
    "for i in list_of_test:\n",
    "    a = i.astype(str)\n",
    "    a= a.values[0]\n",
    "    print(a)\n",
    "    time_logs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_logs = time_logs[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING THE SUBJECTS HEART RATE VAUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrate = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/HR.csv',header=None)\n",
    "hrate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrate[2:].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of heart rate excluding the first two rows\n",
    "hrate[2:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial time_stamp\n",
    "hr_initital_time = int(hrate[0][0])\n",
    "#creating a new pandas dataframe\n",
    "hr_combined_data = pd.DataFrame()\n",
    "#adding the heart_rate values to the dataframe\n",
    "hr_combined_data['heart_rate'] = hrate[2:]\n",
    "#creating the time_stamp for the rest of the values\n",
    "hr_combined_data['utc_time']= range(hr_initital_time,hr_initital_time+len(hr_combined_data['heart_rate']))\n",
    "#resetting the index to start with 0\n",
    "hr_combined_data= hr_combined_data.reset_index()\n",
    "hr_combined_data=hr_combined_data.drop(columns='index')\n",
    "#converting the UTC time to 24 hour format time\n",
    "hr_time_stp = []\n",
    "for i in  hr_combined_data['utc_time']:\n",
    "    c = str(datetime.datetime.fromtimestamp(i).time())\n",
    "    d = datetime.datetime.strptime(c, \"%H:%M:%S\")\n",
    "    a =d.strftime(\"%I:%M:%S\" )\n",
    "    hr_time_stp.append(a)\n",
    "    # hr_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "hr_combined_data['time'] = hr_time_stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined data\n",
    "hr_combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTTING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the heart rate \n",
    "fig, a_x = plt.subplots(figsize=(40, 10))\n",
    "#paramaters \n",
    "y=hr_combined_data['heart_rate']\n",
    "x=hr_combined_data['time']\n",
    "\n",
    "#marking time intervals\n",
    "time = mdates.MinuteLocator(interval=250000)\n",
    "a_x.xaxis.set_major_locator(time) \n",
    "#plotting the graph\n",
    "a_x.plot(x.astype(str), y)\n",
    "# a_x.plot(rolling_mean)\n",
    "# a_x.plot(rolling_mean2)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('heart rate')\n",
    "for t in time_logs:\n",
    "    plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "plt.axhline(y = y.mean(), color = 'b', label = 'axvline - full height')\n",
    "\n",
    "#the vertical lines are the sessions and and the horizontal line respresents the mean value of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING THE SUBJECTS EDA VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the eda data\n",
    "eda = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/EDA.csv',header=None)\n",
    "eda.head()\n",
    "eda_data = eda[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering every 4th element as frequency is 4hz\n",
    "count = 0\n",
    "eda_4 = []\n",
    "for i in eda_data[0]:\n",
    "    if count % 4 == 0:\n",
    "        eda_4.append(i)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initital time stamp\n",
    "eda_initital_time = int(eda[0][0])\n",
    "#creating a pandas datafreame\n",
    "eda_combined_data = pd.DataFrame()\n",
    "#combining the filtered data to the dataframe\n",
    "eda_combined_data['eda'] = eda_4\n",
    "#creating time stamps for the rest of the data\n",
    "eda_combined_data['utc_time']= range(eda_initital_time,eda_initital_time+len(eda_4))\n",
    "eda_combined_data= eda_combined_data.reset_index()\n",
    "eda_combined_data=eda_combined_data.drop(columns='index')\n",
    "#converting UTC to 24 hr format\n",
    "eda_time_stp = []\n",
    "for i in  eda_combined_data['utc_time']:\n",
    "    c = str(datetime.datetime.fromtimestamp(i).time())\n",
    "    d = datetime.datetime.strptime(c, \"%H:%M:%S\")\n",
    "    a =d.strftime(\"%I:%M:%S\" )\n",
    "    eda_time_stp.append(a)\n",
    "    # eda_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "#combining the converted time to the dataframe\n",
    "eda_combined_data['time'] = eda_time_stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined data\n",
    "eda_combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda_combined_data= find_index(eda_combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the eda values\n",
    "fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "#parameters\n",
    "y=eda_combined_data['eda']\n",
    "x=eda_combined_data['time']\n",
    "\n",
    "#marking time intervals\n",
    "loc = mdates.MinuteLocator(interval=250000)\n",
    "a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "#plotting the graph\n",
    "a_x.plot(x.astype(str), y)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('eda')\n",
    "for t in time_logs:\n",
    "    plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "plt.axhline(y = y.mean(), color = 'b', label = 'axvline - full height')\n",
    "#the vertical lines are the sessions and and the horizontal line respresents the mean value of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING THE SUBJECTS ACC VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the ACC data\n",
    "acc = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/ACC.csv',header=None)\n",
    "acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc[2:].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc[2:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING THE SUBJECTS IBI VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the IBI data\n",
    "ibi = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/IBI.csv',header=None)\n",
    "ibi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibi[2:].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibi[1:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initital time stamp\n",
    "ibi_initital_time = int(ibi[0][0])\n",
    "#creating a pandas datafreame\n",
    "ibi_combined_data = pd.DataFrame()\n",
    "#combining the filtered data to the dataframe\n",
    "ibi_combined_data['ibi'] = ibi[1][1:]\n",
    "#creating time stamps for the rest of the data\n",
    "ibi_combined_data['utc_time']= range(ibi_initital_time,ibi_initital_time+len(ibi[1][1:]))\n",
    "ibi_combined_data= ibi_combined_data.reset_index()\n",
    "ibi_combined_data=ibi_combined_data.drop(columns='index')\n",
    "#converting UTC to 24 hr format\n",
    "ibi_time_stp = []\n",
    "for i in  ibi_combined_data['utc_time']:\n",
    "    c = datetime.datetime.fromtimestamp(i)\n",
    "    ibi_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "#combining the converted time to the dataframe\n",
    "ibi_combined_data['time'] = ibi_time_stp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTTING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the ibi values\n",
    "fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "#parameters\n",
    "y=ibi_combined_data['ibi']\n",
    "x=ibi_combined_data['time']\n",
    "#marking time intervals\n",
    "loc = mdates.MinuteLocator(interval=250000)\n",
    "a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "#plotting the graph\n",
    "a_x.plot(x, y)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('ibi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING THE SUBJECTS BVP VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the BVP data\n",
    "bvp = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/BVP.csv',header=None)\n",
    "bvp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvp[2:].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvp[2:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTTING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the graph\n",
    "x = bvp[2:]\n",
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/TEMP.csv',header=None)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = temp[2:]\n",
    "temp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering every 4th element as frequency is 4hz\n",
    "count = 0\n",
    "temp_4 = []\n",
    "for i in temp_data[0]:\n",
    "    if count % 4 == 0:\n",
    "        temp_4.append(i)\n",
    "    count +=1\n",
    "#initital time stamp\n",
    "temp_initital_time = int(temp[0][0])\n",
    "#creating a pandas datafreame\n",
    "temp_combined_data = pd.DataFrame()\n",
    "#combining the filtered data to the dataframe\n",
    "temp_combined_data['temp'] = temp_4\n",
    "#creating time stamps for the rest of the data\n",
    "temp_combined_data['utc_time']= range(temp_initital_time,temp_initital_time+len(temp_4))\n",
    "temp_combined_data= temp_combined_data.reset_index()\n",
    "temp_combined_data=temp_combined_data.drop(columns='index')\n",
    "#converting UTC to 24 hr format\n",
    "temp_time_stp = []\n",
    "for i in  temp_combined_data['utc_time']:\n",
    "    c = str(datetime.datetime.fromtimestamp(i).time())\n",
    "    d = datetime.datetime.strptime(c, \"%H:%M:%S\")\n",
    "    a =d.strftime(\"%I:%M:%S\" )\n",
    "    temp_time_stp.append(a)\n",
    "    # eda_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "#combining the converted time to the dataframe\n",
    "temp_combined_data['time'] = temp_time_stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_combined_data= find_index(temp_combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the eda values\n",
    "fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "#parameters\n",
    "y=temp_combined_data['temp']\n",
    "x=temp_combined_data['time']\n",
    "# rolling_mean_eda = y.rolling(window=200).mean()\n",
    "\n",
    "#marking time intervals\n",
    "loc = mdates.MinuteLocator(interval=250000)\n",
    "a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "#plotting the graph\n",
    "a_x.plot(x.astype(str), y)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('temp')\n",
    "# plt.plot(rolling_mean_eda)\n",
    "for t in time_logs:\n",
    "    plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "plt.axhline(y = y.mean(), color = 'b', label = 'axvline - full height')\n",
    "#the vertical lines are the sessions and and the horizontal line respresents the mean value of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING TAG VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/tags_S{num}.csv',header=None)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergind the heart rate, EDA and temperature values on time\n",
    "final_df = pd.merge(hr_combined_data,eda_combined_data,how='outer', on='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df,temp_combined_data,how='outer', on='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_combined_data.shape,eda_combined_data.shape,temp_combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the table based on index\n",
    "final_df = final_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping any null values\n",
    "final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only necessary colmns\n",
    "final_df= final_df[['heart_rate','eda','temp','time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e =final_df[['time']].values\n",
    "e[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling the stress indusing sessions as 1 and 0 for rest and baseline periosds\n",
    "lable_list=[]\n",
    "k =0\n",
    "lable = 0\n",
    "for i in e:\n",
    "    if k <6:\n",
    "        if str(i[0]) == time_logs[k]:\n",
    "            # print('same')\n",
    "            if k%2 ==0:\n",
    "                lable = 1\n",
    "                # print('lable',lable)\n",
    "                k +=1\n",
    "            else:\n",
    "                lable = 0\n",
    "                k +=1\n",
    "    lable_list.append(lable)\n",
    "    # print(i,lable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['lable']=lable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "#parameters\n",
    "y=final_df['lable']\n",
    "x=final_df['time']\n",
    "#marking time intervals\n",
    "loc = mdates.MinuteLocator(interval=250000)\n",
    "a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "#plotting the graph\n",
    "# a_x.plot(x,y)\n",
    "a_x.plot(x.astype(str), y)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('ibi')\n",
    "\n",
    "for t in time_logs:\n",
    "    plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "\n",
    "#the intervals with stressed period are marked 1 and the rest are marked 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the summary of data when the individual is stressd.\n",
    "final_df[final_df['lable']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df['lable']==1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the summary of data when the individual is not stressd.\n",
    "\n",
    "final_df[final_df['lable']==0].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be observed here that the heart rate, eda and temp values are higher during streesed period compared to the rest and baselineperiod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkin for correlationg between the features\n",
    "cor = final_df.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['heart_rate','eda','temp']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data for training and testing purpose\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    final_df[['heart_rate','eda','temp']].values,final_df['lable'].values , test_size=0.3,random_state=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardising the data for easy computation\n",
    "sc = StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perforing crossvalidaion using the random forest clssifier\n",
    "cv = cross_val_score(RandomForestClassifier(),X_train,y_train,cv=10)\n",
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perforing crossvalidaion using the random  logistic regressor\n",
    "cv = cross_val_score(LogisticRegression(),X_train,y_train,cv=10)\n",
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perforing crossvalidaion using the random forest knegihbours\n",
    "cv = cross_val_score(KNeighborsClassifier(),X_train,y_train,cv=10)\n",
    "cv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be observed that in many cases the random forest classifer performed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pipeline.\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('lr', RandomForestClassifier()),])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be observed that the number of time the model has predicted not stressed while the individual was actully and the number of times the model predicted that the individual was not stressed is very less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be observed that the accuracy_score is consistantly above 80 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_hr_mean_0 = []\n",
    "list_eda_mean_0 = []\n",
    "list_temp_mean_0 = []\n",
    "list_hr_mean_1 = []\n",
    "list_eda_mean_1 = []\n",
    "list_temp_mean_1 = []\n",
    "random_f=[]\n",
    "lg=[]\n",
    "kn=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### run this cell twice.\n",
    "### first run the for loop with range(1,10) and then change the 13th row from  num=f'{i}' to num =f'0{i}' and run again with range (10,36) to college the data of all the subjects\n",
    "for i in range (1,10): \n",
    "    #importing the required libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import datetime\n",
    "    import matplotlib.dates as mdates\n",
    "    from scipy import signal\n",
    "\n",
    "    #please change the value to access subject details. eg: '02' , '08', '20'\n",
    "    num =f'0{i}'\n",
    "    time_logs = pd.read_excel('/Users/karthikningala/CE888-DATA SCIENCE AND DECISION MAKING/time_logs.xlsx')\n",
    "    # /Users/karthikningala/CE888-DATA SCIENCE AND DECISION MAKING/Time_logs.xlsx\n",
    "    time_logs.head()\n",
    "    #dividing the time logs into intervals\n",
    "    s=time_logs.loc[time_logs['S. ID.']==f'S{num}']\n",
    "    stroop_test = s['Stroop Test']\n",
    "    relax1 = s['Relax']\n",
    "    interview=s['Interview']\n",
    "    relax2=s['Relax.1']\n",
    "    hyperventilation = s['Hyperventilation']\n",
    "    relax3 = s['Relax.2']\n",
    "\n",
    "    list_of_test = [stroop_test,relax1,interview,relax2,hyperventilation,relax3]\n",
    "    time_logs = []\n",
    "    stroop_test.astype(str).values[0]\n",
    "    for i in list_of_test:\n",
    "        a = i.astype(str)\n",
    "        a= a.values[0]\n",
    "        print(a)\n",
    "        time_logs.append(a)\n",
    "    time_logs = time_logs[:6]\n",
    "    # READING THE SUBJECTS HEART RATE VAUES\n",
    "    hrate = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/HR.csv',header=None)\n",
    "    hrate.head()\n",
    "    # DATA ANALYSIS\n",
    "    hrate[2:].info()\n",
    "    #summary of heart rate excluding the first two rows\n",
    "    hrate[2:].describe()\n",
    "    # DATA PROCESSING\n",
    "    #initial time_stamp\n",
    "    hr_initital_time = int(hrate[0][0])\n",
    "    #creating a new pandas dataframe\n",
    "    hr_combined_data = pd.DataFrame()\n",
    "    #adding the heart_rate values to the dataframe\n",
    "    hr_combined_data['heart_rate'] = hrate[2:]\n",
    "    #creating the time_stamp for the rest of the values\n",
    "    hr_combined_data['utc_time']= range(hr_initital_time,hr_initital_time+len(hr_combined_data['heart_rate']))\n",
    "    #resetting the index to start with 0\n",
    "    hr_combined_data= hr_combined_data.reset_index()\n",
    "    hr_combined_data=hr_combined_data.drop(columns='index')\n",
    "    #converting the UTC time to 24 hour format time\n",
    "    hr_time_stp = []\n",
    "    for i in  hr_combined_data['utc_time']:\n",
    "        c = str(datetime.datetime.fromtimestamp(i).time())\n",
    "        d = datetime.datetime.strptime(c, \"%H:%M:%S\")\n",
    "        a =d.strftime(\"%I:%M:%S\" )\n",
    "        hr_time_stp.append(a)\n",
    "        # hr_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "    hr_combined_data['time'] = hr_time_stp\n",
    "    #combined data\n",
    "    hr_combined_data\n",
    "    # PLOTTING THE DATA\n",
    "    #plotting the heart rate \n",
    "    fig, a_x = plt.subplots(figsize=(40, 10))\n",
    "    #paramaters \n",
    "    y=hr_combined_data['heart_rate']\n",
    "    x=hr_combined_data['time']\n",
    "\n",
    "    #marking time intervals\n",
    "    time = mdates.MinuteLocator(interval=250000)\n",
    "    a_x.xaxis.set_major_locator(time) \n",
    "    #plotting the graph\n",
    "    a_x.plot(x.astype(str), y)\n",
    "    # a_x.plot(rolling_mean)\n",
    "    # a_x.plot(rolling_mean2)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('heart rate')\n",
    "    for t in time_logs:\n",
    "        plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "    plt.axhline(y = y.mean(), color = 'b', label = 'axvline - full height')\n",
    "\n",
    "    #the vertical lines are the sessions and and the horizontal line respresents the mean value of the data.\n",
    "    # READING THE SUBJECTS EDA VALUES\n",
    "    #reading the eda data\n",
    "    eda = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/EDA.csv',header=None)\n",
    "    eda.head()\n",
    "    eda_data = eda[2:]\n",
    "    # DATA ANALYSIS\n",
    "    eda_data.info()\n",
    "    eda_data.describe()\n",
    "    # DATA PROCESSING\n",
    "    #filtering every 4th element as frequency is 4hz\n",
    "    count = 0\n",
    "    eda_4 = []\n",
    "    for i in eda_data[0]:\n",
    "        if count % 4 == 0:\n",
    "            eda_4.append(i)\n",
    "        count +=1\n",
    "    #initital time stamp\n",
    "    eda_initital_time = int(eda[0][0])\n",
    "    #creating a pandas datafreame\n",
    "    eda_combined_data = pd.DataFrame()\n",
    "    #combining the filtered data to the dataframe\n",
    "    eda_combined_data['eda'] = eda_4\n",
    "    #creating time stamps for the rest of the data\n",
    "    eda_combined_data['utc_time']= range(eda_initital_time,eda_initital_time+len(eda_4))\n",
    "    eda_combined_data= eda_combined_data.reset_index()\n",
    "    eda_combined_data=eda_combined_data.drop(columns='index')\n",
    "    #converting UTC to 24 hr format\n",
    "    eda_time_stp = []\n",
    "    for i in  eda_combined_data['utc_time']:\n",
    "        c = str(datetime.datetime.fromtimestamp(i).time())\n",
    "        d = datetime.datetime.strptime(c, \"%H:%M:%S\")\n",
    "        a =d.strftime(\"%I:%M:%S\" )\n",
    "        eda_time_stp.append(a)\n",
    "        # eda_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "    #combining the converted time to the dataframe\n",
    "    eda_combined_data['time'] = eda_time_stp\n",
    "    #combined data\n",
    "    eda_combined_data\n",
    "    # eda_combined_data= find_index(eda_combined_data)\n",
    "    #plotting the eda values\n",
    "    fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "    #parameters\n",
    "    y=eda_combined_data['eda']\n",
    "    x=eda_combined_data['time']\n",
    "\n",
    "    #marking time intervals\n",
    "    loc = mdates.MinuteLocator(interval=250000)\n",
    "    a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "    #plotting the graph\n",
    "    a_x.plot(x.astype(str), y)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('eda')\n",
    "    for t in time_logs:\n",
    "        plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "    plt.axhline(y = y.mean(), color = 'b', label = 'axvline - full height')\n",
    "    #the vertical lines are the sessions and and the horizontal line respresents the mean value of the data.\n",
    "    # READING THE SUBJECTS ACC VALUES\n",
    "    #reading the ACC data\n",
    "    acc = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/ACC.csv',header=None)\n",
    "    acc.head()\n",
    "    # DATA ANALYSIS\n",
    "    acc[2:].info()\n",
    "    acc[2:].describe()\n",
    "    # READING THE SUBJECTS IBI VALUES\n",
    "    #reading the IBI data\n",
    "    ibi = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/IBI.csv',header=None)\n",
    "    ibi.head()\n",
    "    # DATA ANALYSIS\n",
    "    ibi[2:].info()\n",
    "    ibi[1:].describe()\n",
    "    # DATA PROCESSING\n",
    "    #initital time stamp\n",
    "    ibi_initital_time = int(ibi[0][0])\n",
    "    #creating a pandas datafreame\n",
    "    ibi_combined_data = pd.DataFrame()\n",
    "    #combining the filtered data to the dataframe\n",
    "    ibi_combined_data['ibi'] = ibi[1][1:]\n",
    "    #creating time stamps for the rest of the data\n",
    "    ibi_combined_data['utc_time']= range(ibi_initital_time,ibi_initital_time+len(ibi[1][1:]))\n",
    "    ibi_combined_data= ibi_combined_data.reset_index()\n",
    "    ibi_combined_data=ibi_combined_data.drop(columns='index')\n",
    "    #converting UTC to 24 hr format\n",
    "    ibi_time_stp = []\n",
    "    for i in  ibi_combined_data['utc_time']:\n",
    "        c = datetime.datetime.fromtimestamp(i)\n",
    "        ibi_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "    #combining the converted time to the dataframe\n",
    "    ibi_combined_data['time'] = ibi_time_stp\n",
    "    # PLOTTING THE DATA\n",
    "    #plotting the ibi values\n",
    "    fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "    #parameters\n",
    "    y=ibi_combined_data['ibi']\n",
    "    x=ibi_combined_data['time']\n",
    "    #marking time intervals\n",
    "    loc = mdates.MinuteLocator(interval=250000)\n",
    "    a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "    #plotting the graph\n",
    "    a_x.plot(x, y)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('ibi')\n",
    "    # READING THE SUBJECTS BVP VALUES\n",
    "    #reading the BVP data\n",
    "    bvp = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/BVP.csv',header=None)\n",
    "    bvp.head()\n",
    "    # DATA ANALYSIS\n",
    "    bvp[2:].info()\n",
    "    bvp[2:].describe()\n",
    "    # PLOTTING THE DATA\n",
    "    #plotting the graph\n",
    "    x = bvp[2:]\n",
    "    plt.plot(x)\n",
    "    plt.show()\n",
    "    temp = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/TEMP.csv',header=None)\n",
    "    temp.head()\n",
    "    temp_data = temp[2:]\n",
    "    temp_data.head()\n",
    "    #filtering every 4th element as frequency is 4hz\n",
    "    count = 0\n",
    "    temp_4 = []\n",
    "    for i in temp_data[0]:\n",
    "        if count % 4 == 0:\n",
    "            temp_4.append(i)\n",
    "        count +=1\n",
    "    #initital time stamp\n",
    "    temp_initital_time = int(temp[0][0])\n",
    "    #creating a pandas datafreame\n",
    "    temp_combined_data = pd.DataFrame()\n",
    "    #combining the filtered data to the dataframe\n",
    "    temp_combined_data['temp'] = temp_4\n",
    "    #creating time stamps for the rest of the data\n",
    "    temp_combined_data['utc_time']= range(temp_initital_time,temp_initital_time+len(temp_4))\n",
    "    temp_combined_data= temp_combined_data.reset_index()\n",
    "    temp_combined_data=temp_combined_data.drop(columns='index')\n",
    "    #converting UTC to 24 hr format\n",
    "    temp_time_stp = []\n",
    "    for i in  temp_combined_data['utc_time']:\n",
    "        c = str(datetime.datetime.fromtimestamp(i).time())\n",
    "        d = datetime.datetime.strptime(c, \"%H:%M:%S\")\n",
    "        a =d.strftime(\"%I:%M:%S\" )\n",
    "        temp_time_stp.append(a)\n",
    "        # eda_time_stp.append(f'{c.hour}:{c.minute}:{c.second}')\n",
    "    #combining the converted time to the dataframe\n",
    "    temp_combined_data['time'] = temp_time_stp\n",
    "    temp_combined_data\n",
    "    # temp_combined_data= find_index(temp_combined_data)\n",
    "    #plotting the eda values\n",
    "    fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "    #parameters\n",
    "    y=temp_combined_data['temp']\n",
    "    x=temp_combined_data['time']\n",
    "    # rolling_mean_eda = y.rolling(window=200).mean()\n",
    "\n",
    "    #marking time intervals\n",
    "    loc = mdates.MinuteLocator(interval=250000)\n",
    "    a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "    #plotting the graph\n",
    "    a_x.plot(x.astype(str), y)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('temp')\n",
    "    # plt.plot(rolling_mean_eda)\n",
    "    for t in time_logs:\n",
    "        plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "    plt.axhline(y = y.mean(), color = 'b', label = 'axvline - full height')\n",
    "    #the vertical lines are the sessions and and the horizontal line respresents the mean value of the data.\n",
    "    # READING TAG VALUES\n",
    "    tags = pd.read_csv(f'https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S{num}/tags_S{num}.csv',header=None)\n",
    "    tags.head()\n",
    "    final_df = pd.merge(hr_combined_data,eda_combined_data,how='outer', on='time')\n",
    "    final_df = pd.merge(final_df,temp_combined_data,how='outer', on='time')\n",
    "    hr_combined_data.shape,eda_combined_data.shape,temp_combined_data.shape\n",
    "    final_df\n",
    "    final_df = final_df.sort_index()\n",
    "    final_df = final_df.dropna()\n",
    "    final_df= final_df[['heart_rate','eda','temp','time']]\n",
    "    e =final_df[['time']].values\n",
    "    e[0][0]\n",
    "    time_logs\n",
    "    final_df\n",
    "    # lable_list=[]\n",
    "    # for i, j in final_df[['heart_rate','eda']].values:\n",
    "    #     # print(i,j)\n",
    "    #     if i > final_df['heart_rate'].values.mean() and j>final_df['eda'].values.mean():\n",
    "    #         lable =1\n",
    "    #     else:\n",
    "    #         lable = 0\n",
    "    #     lable_list.append(lable)\n",
    "    time_logs[1]\n",
    "    lable_list=[]\n",
    "    k =0\n",
    "    lable = 0\n",
    "    for i in e:\n",
    "        if k <6:\n",
    "            if str(i[0]) == time_logs[k]:\n",
    "                # print('same')\n",
    "                if k%2 ==0:\n",
    "                    lable = 1\n",
    "                    # print('lable',lable)\n",
    "                    k +=1\n",
    "                else:\n",
    "                    lable = 0\n",
    "                    k +=1\n",
    "        lable_list.append(lable)\n",
    "        # print(i,lable)\n",
    "\n",
    "    final_df['lable']=lable_list\n",
    "    print(final_df.to_string())\n",
    "    fig, a_x = plt.subplots(figsize=(40, 6))\n",
    "    #parameters\n",
    "    y=final_df['lable']\n",
    "    x=final_df['time']\n",
    "    #marking time intervals\n",
    "    loc = mdates.MinuteLocator(interval=250000)\n",
    "    a_x.xaxis.set_major_locator(loc) # Locator for major axis only.\n",
    "    #plotting the graph\n",
    "    # a_x.plot(x,y)\n",
    "    a_x.plot(x.astype(str), y)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('ibi')\n",
    "\n",
    "    for t in time_logs:\n",
    "        plt.axvline(x = t, color = 'b', label = 'axvline - full height')\n",
    "\n",
    "    #the intervals with stressed period are marked 1 and the rest are marked 0.\n",
    "    #the summary of data when the individual is stressd.\n",
    "    final_df[final_df['lable']==1].describe()\n",
    "    #the summary of data when the individual is not stressd.\n",
    "\n",
    "    final_df[final_df['lable']==0].describe()\n",
    "\n",
    "    # it can be observed here that the heart rate, eda and temp values are higher during streesed period compared to the rest and baselineperiod.\n",
    "    # checkin for correlationg between the features\n",
    "    cor = final_df.corr()\n",
    "    cor\n",
    "    final_df[['heart_rate','eda','temp']].values\n",
    "    # Machine Learning Model\n",
    "    # importing the required libraries\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import numpy as np\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.metrics import r2_score, accuracy_score\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # splitting the data for training and testing purpose\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        final_df[['heart_rate','eda','temp']].values,final_df['lable'].values , test_size=0.3,random_state=54)\n",
    "    # standardising the data for easy computation\n",
    "    sc = StandardScaler()\n",
    "    X_train=sc.fit_transform(X_train)\n",
    "    X_test=sc.fit_transform(X_test)\n",
    "    # perforing crossvalidaion using the random forest clssifier\n",
    "    cv_rf = cross_val_score(RandomForestClassifier(),X_train,y_train,cv=10)\n",
    "    cv_rf.mean()\n",
    "    # perforing crossvalidaion using the random  logistic regressor\n",
    "    cv_lg = cross_val_score(LogisticRegression(),X_train,y_train,cv=10)\n",
    "    cv_lg.mean()\n",
    "    # perforing crossvalidaion using the random forest knegihbours\n",
    "    cv_kn = cross_val_score(KNeighborsClassifier(),X_train,y_train,cv=10)\n",
    "    cv_kn.mean()\n",
    "    # it can be observed that in many cases the random forest classifer performed well.\n",
    "    # creating a pipeline.\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('lr', RandomForestClassifier()),])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.score(X_test, y_test)\n",
    "    # Making predicitons\n",
    "    y_pred =pipe.predict(X_test)\n",
    "    # Checking its performance\n",
    "    confusion_matrix(y_test,y_pred)\n",
    "    # it can be observed that the number of time the model has predicted not stressed while the individual was actully and the number of times the model predicted that the individual was not stressed is very less.\n",
    "    accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    aa=final_df[final_df['lable']==1].mean()[0]\n",
    "    bb=final_df[final_df['lable']==1].mean()[1]\n",
    "    cc= final_df[final_df['lable']==1].mean()[2]\n",
    "\n",
    "    dd=final_df[final_df['lable']==0].mean()[0]\n",
    "    ee=final_df[final_df['lable']==0].mean()[1]\n",
    "    ff=final_df[final_df['lable']==0].mean()[2]\n",
    "    list_hr_mean_1.append(aa)\n",
    "    list_eda_mean_1.append(bb)\n",
    "    list_temp_mean_1.append(cc)\n",
    "    list_hr_mean_0.append(dd)\n",
    "    list_eda_mean_0.append(ee)\n",
    "    list_temp_mean_0.append(ff)\n",
    "    random_f.append(cv_rf.mean())\n",
    "    lg.append(cv_lg.mean())\n",
    "    kn.append(cv_kn.mean())\n",
    "\n",
    "list_hr_mean_0  = np.array(list_hr_mean_0)\n",
    "list_eda_mean_0 = np.array(list_eda_mean_0)\n",
    "list_temp_mean_0= np.array(list_temp_mean_0)\n",
    "list_hr_mean_1= np.array(list_hr_mean_1)\n",
    "list_eda_mean_1 = np.array(list_eda_mean_1)\n",
    "list_temp_mean_1 = np.array(list_temp_mean_1)\n",
    "random_f= np.array(random_f)\n",
    "lg =np.array(lg)\n",
    "kn=np.array(kn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the mean values when not stressed\n",
    "values = [list_hr_mean_0.mean(), list_eda_mean_0.mean(), list_temp_mean_0.mean()]\n",
    "labels = ['heart_rate 1', 'eda 2', 'temp 3']\n",
    "\n",
    "plt.bar(labels, values)\n",
    "plt.xlabel(\"not stressed\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the mean values when stressed\n",
    "\n",
    "values = [list_hr_mean_1.mean(), list_eda_mean_1.mean(), list_temp_mean_1.mean()]\n",
    "labels = ['heart_rate 1', 'eda 2', 'temp 3']\n",
    "\n",
    "plt.bar(labels, values)\n",
    "plt.xlabel(\"stressed\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the mean performances of classifiers\n",
    "\n",
    "values = [random_f.mean()*100, lg.mean()*100, kn.mean()*100]\n",
    "labels = ['random forest', 'logistic reg', 'Knearest']\n",
    "\n",
    "plt.bar(labels, values)\n",
    "plt.title(\"Performance of classifiers\")\n",
    "plt.ylabel(\"values\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8d63dd93a4b4afeb2200e09442bb31fcd50714eca20d7d158ba29a44eaae20c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
